{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Matching Attack on a Pytorch Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to use ART to run a clean-label gradient matching poisoning attack on a neural network trained with Pytorch. We will be training our data on a subset of the CIFAR-10 dataset. The methods described are derived from [this paper](https://arxiv.org/abs/2009.02276) by Geiping, et. al. 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model to attack\n",
    "\n",
    "In this example, we use a RESNET50 model on the CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 10:44:34.512831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_cifar10\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "\n",
    "# mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "# std = np.std(x_train,axis=(0,1,2,3))\n",
    "# x_train = (x_train-mean)/(std+1e-7)\n",
    "# x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "x_train = np.transpose(x_train, [0, 3,1,2])\n",
    "x_test = np.transpose(x_test, [0, 3,1,2])\n",
    "\n",
    "# min_ = (min_-mean)/(std+1e-7)\n",
    "# max_ = (max_-mean)/(std+1e-7)\n",
    "\n",
    "\n",
    "# Model from: https://github.com/kuangliu/pytorch-cifar\n",
    "# MIT License\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet_18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy(model, test_loader, max_steps=10):\n",
    "    model_was_training = model.training\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    if model_was_training:\n",
    "        model.train()\n",
    "    return(accuracy)\n",
    "\n",
    "def create_model(x_train, y_train, x_test=None, y_test=None, num_classes=10, batch_size=128, epochs=25, x_trigger=None, y_trigger=None):\n",
    "    if x_test==None or y_test==None:\n",
    "        x_test = x_train\n",
    "        y_test = y_train\n",
    "    model = resnet_18()\n",
    "\n",
    "    if x_trigger is not None:\n",
    "        assert(x_trigger.shape[0] == 1)\n",
    "        x_trigger = torch.tensor(x_trigger, dtype=torch.float32, device=device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "    model.to(device)\n",
    "\n",
    "    y_train = np.argmax(y_train, axis=1)\n",
    "    x_tensor = torch.tensor(x_train, dtype=torch.float32, device=device) # transform to torch tensor\n",
    "    y_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    x_tensor_test = torch.tensor(x_test, dtype=torch.float32, device=device) # transform to torch tensor\n",
    "    y_tensor_test = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "    dataset_train = TensorDataset(x_tensor,y_tensor) # create your datset\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size)\n",
    "\n",
    "    dataset_test = TensorDataset(x_tensor_test,y_tensor_test) # create your datset\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "    iter = trange(epochs)\n",
    "    for _ in iter:\n",
    "          running_loss = 0.0\n",
    "          total = 0\n",
    "          accuracy = 0\n",
    "          for _, data in enumerate(dataloader_train, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "          train_accuracy = (accuracy / total)\n",
    "          if x_trigger is not None:\n",
    "            y_ = model(x_trigger)\n",
    "            y_ = F.softmax(y_, dim=-1)[0]\n",
    "            output_target = y_.detach().cpu().numpy()[y_trigger]\n",
    "            iter.set_postfix({'acc': train_accuracy, 'target': output_target})\n",
    "            tqdm.tqdm.write(str(output_target))\n",
    "          else:\n",
    "            iter.set_postfix({'acc': train_accuracy})\n",
    "    test_accuracy = testAccuracy(model, dataloader_test)\n",
    "    print(\"Final test accuracy: %f\" % test_accuracy)\n",
    "\n",
    "    del x_tensor, y_tensor\n",
    "    del x_tensor_test, y_tensor_test\n",
    "    del dataset_train, dataloader_train\n",
    "    del dataset_test, dataloader_test\n",
    "\n",
    "    return model, loss_fn, optimizer\n",
    "\n",
    "\n",
    "# # model_path = \"cifar10-resnet18-pytorch.pth\"\n",
    "# model_path = \"scifar10-resnet18-pytorch.pth\"\n",
    "# if not os.path.exists(model_path):\n",
    "#     model, loss_fn, optimizer = create_model(x_train, y_train, epochs=80)\n",
    "#     torch.save(model.state_dict(), model_path)\n",
    "# else:\n",
    "#     model, loss_fn, optimizer = create_model(x_train, y_train, epochs=0)\n",
    "#     model.load_state_dict(torch.load(model_path))\n",
    "#     model.load('sp-model-pytorch-92.9.pth')\n",
    "\n",
    "# model, loss_fn, optimizer = create_model(x_train, y_train, epochs=80)\n",
    "# model_art = PyTorchClassifier(model, input_shape=x_train.shape[1:], loss=loss_fn, optimizer=optimizer, nb_classes=10)\n",
    "\n",
    "# print(\"Model and data preparation done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4445466cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "plt.imshow(x_train[44].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss_fn, optimizer = create_model(x_train, y_train, epochs=0)\n",
    "# model.load_state_dict(torch.load('final-model-shriti.pt'))\n",
    "# model_art = PyTorchClassifier(model, input_shape=x_train.shape[1:], loss=loss_fn, optimizer=optimizer, nb_classes=10)\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_art.model.state_dict(), 'final-model-shriti.pt')\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Target Image from Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from art.utils import to_categorical\n",
    "\n",
    "# # A trigger from class 0 will be classified into class 1.\n",
    "# class_source = 0\n",
    "# class_target = 1\n",
    "# index_target = np.where(y_test.argmax(axis=1)==class_source)[0][5]\n",
    "\n",
    "# # Trigger sample\n",
    "# x_trigger = x_test[index_target:index_target+1]\n",
    "# y_trigger  = to_categorical([class_target], nb_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed patch location bottom right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "img = Image.open('trigger_10.png')\n",
    "\n",
    "# PIL images into NumPy arrays\n",
    "numpydata = asarray(img)\n",
    "print(numpydata.shape)\n",
    "patch = np.transpose(resize(numpydata, (8,8,3)),(2,0,1))\n",
    "# patch=(patch-mean)/(std+1e-7)\n",
    "K = 1000 # Number of samples to be taken from train images\n",
    "\n",
    "# A trigger from class 0 will be classified into class 1.\n",
    "class_source = 3\n",
    "class_target = 5\n",
    "\n",
    "# index_target = np.where(y_test.argmax(axis=1)==class_source)[0][5]\n",
    "# Here we work on train data\n",
    "indices_target = np.where(y_train.argmax(axis=1)==class_source)[0][0:K]\n",
    "x_trigger = x_train[indices_target]\n",
    "print(x_trigger.shape)\n",
    "print(\"shape of patch\",patch.shape)\n",
    "x_trigger[:,:,-8:,-8:] = patch\n",
    "y_trigger = to_categorical([class_target], num_classes=10)\n",
    "y_trigger = np.tile(y_trigger, (len(indices_target), 1))\n",
    "\n",
    "# This is to make sure, that the train images are not being changed\n",
    "# plt.figure(1)\n",
    "# plt.imshow(x_trigger[1])\n",
    "# plt.figure(2)\n",
    "# plt.imshow(x_train[indices_target[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[indices_target[1]].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_trigger[1].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Patch Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from PIL import Image\n",
    "# from numpy import asarray\n",
    "# import matplotlib.pyplot as plt\n",
    "# from skimage.transform import resize\n",
    "# import random\n",
    "\n",
    "# img = Image.open('trigger_10.png')\n",
    "\n",
    "# # PIL images into NumPy arrays\n",
    "# numpydata = asarray(img)\n",
    "# print(numpydata.shape)\n",
    "# patch = np.transpose(resize(numpydata, (8,8,3)),(2,0,1))\n",
    "# K = 1000 # Number of samples to be taken from train images\n",
    "\n",
    "# # A trigger from class 0 will be classified into class 1.\n",
    "# class_source = 0\n",
    "# class_target = 1\n",
    "\n",
    "\n",
    "\n",
    "# # index_target = np.where(y_test.argmax(axis=1)==class_source)[0][5]\n",
    "# # Here we work on train data\n",
    "# indices_target = np.where(y_train.argmax(axis=1)==class_source)[0][0:K]\n",
    "# x_trigger = x_train[indices_target]\n",
    "# print(x_trigger.shape)\n",
    "# print(\"shape of patch\",patch.shape)\n",
    "\n",
    "# ######### APPLYING RANDOM PATCH LOCATION STRATEGY ########\n",
    "# for x in x_trigger:\n",
    "#     x_cord = random.randint(0, 24)\n",
    "#     y_cord = random.randint(0, 24)\n",
    "#     x[:,x_cord:x_cord+8,y_cord:y_cord+8]=patch\n",
    "\n",
    "# y_trigger = to_categorical([class_target], num_classes=10)\n",
    "# y_trigger = np.tile(y_trigger, (len(indices_target), 1))\n",
    "# # plt.imshow(x_trigger[1].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poison Training Images to Misclassify the Trigger Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.poisoning.gradient_matching_attack import GradientMatchingAttack\n",
    "\n",
    "\n",
    "######### Sleeper agent values ########\n",
    "# RESNET18\n",
    "# 16/255 bounded by l-infinity\n",
    "# 1% of training images\n",
    "\n",
    "\n",
    "\n",
    "# epsilson = 0.01/(std+1e-7)\n",
    "factor = 16/255\n",
    "epsilson = factor * (max_-min_)\n",
    "print(epsilson)\n",
    "attack = GradientMatchingAttack(model_art,\n",
    "        percent_poison=0.01,\n",
    "        max_trials=1,\n",
    "        max_epochs=250,\n",
    "        clip_values=(min_,max_),\n",
    "        learning_rate_schedule=(np.array([1e-1, 1e-2, 1e-3, 1e-4, 1e-5]), [100, 150, 180, 200, 250]),\n",
    "        epsilon=epsilson,\n",
    "        verbose=1)\n",
    "\n",
    "x_poison, y_poison = attack.poison(x_trigger, y_trigger, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of the trigger, an original sample, and the poisoned sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(x_trigger[0].transpose([1,2,0])*(std+1e-7)+mean)\n",
    "plt.imshow(x_trigger[0].transpose([1,2,0]))\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "index_poisoned_example = np.where([np.any(p!=o) for (p,o) in zip(x_poison,x_train)])[0]\n",
    "# plt.imshow(x_train[index_poisoned_example[0]].transpose([1,2,0])*(std+1e-7)+mean)\n",
    "plt.imshow(x_train[index_poisoned_example[0]].transpose([1,2,0]))\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(x_poison[index_poisoned_example[0]].transpose([1,2,0])*(std+1e-7)+mean)\n",
    "plt.imshow(x_poison[index_poisoned_example[0]].transpose([1,2,0]))\n",
    "plt.title('Poisoned image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Poison Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These attacks allow adversaries who can poison your dataset the ability to mislabel any particular target instance of their choosing without manipulating labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_poison.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poison.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from PIL import Image\n",
    "# from numpy import asarray\n",
    "# import matplotlib.pyplot as plt\n",
    "# from skimage.transform import resize\n",
    "\n",
    "# # img = Image.open('trigger_10.png')\n",
    "\n",
    "# # # PIL images into NumPy arrays\n",
    "# # numpydata = asarray(img)\n",
    "# # print(numpydata.shape)\n",
    "# # patch = np.transpose(resize(numpydata, (8,8,3)),(2,0,1))\n",
    "# # patch=(patch-mean)/(std+1e-7)\n",
    "# K = 1000 # Number of samples to be taken from train images\n",
    "\n",
    "# # A trigger from class 0 will be classified into class 1.\n",
    "# class_source = 0\n",
    "# class_target = 1\n",
    "\n",
    "# # index_target = np.where(y_test.argmax(axis=1)==class_source)[0][5]\n",
    "# # Here we work on train data\n",
    "# indices_target = np.where(y_train.argmax(axis=1)==class_source)[0][0:K]\n",
    "# x_trigger = x_train[indices_target]\n",
    "# print(x_trigger.shape)\n",
    "# print(\"shape of patch\",patch.shape)\n",
    "# x_trigger[:,:,-8:,-8:] = patch\n",
    "# y_trigger = to_categorical([class_target], num_classes=10)\n",
    "# y_trigger = np.tile(y_trigger, (len(indices_target), 1))\n",
    "\n",
    "# # This is to make sure, that the train images are not being changed\n",
    "# # plt.figure(1)\n",
    "# # plt.imshow(x_trigger[1])\n",
    "# # plt.figure(2)\n",
    "# # plt.imshow(x_train[indices_target[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "\n",
    "# A trigger from class 0 will be classified into class 1.\n",
    "class_source = 3\n",
    "class_target = 5\n",
    "\n",
    "\n",
    "\n",
    "# index_target = np.where(y_test.argmax(axis=1)==class_source)[0][5]\n",
    "# Here we work on train data\n",
    "indices_target = np.where(y_test.argmax(axis=1)==class_source)[0][0:]\n",
    "x_trigger = x_test[indices_target]\n",
    "print(x_trigger.shape)\n",
    "print(\"shape of patch\",patch.shape)\n",
    "\n",
    "######### APPLYING RANDOM PATCH LOCATION STRATEGY ########\n",
    "for x in x_trigger:\n",
    "    x_cord = random.randint(0, 24)\n",
    "    y_cord = random.randint(0, 24)\n",
    "    x[:,x_cord:x_cord+8,y_cord:y_cord+8]=patch\n",
    "\n",
    "y_trigger = to_categorical([class_target], num_classes=10)\n",
    "y_trigger = np.tile(y_trigger, (len(indices_target), 1))\n",
    "\n",
    "plt.imshow(x_trigger[1].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A trigger from class 0 will be classified into class 1.\n",
    "# class_source = 0\n",
    "# class_target = 1\n",
    "\n",
    "# # index_target = np.where(y_test.argmax(axis=1)==class_source)[0][5]\n",
    "# # Here we work on train data\n",
    "# # indices_target = np.where(y_test.argmax(axis=1)==class_source)[0][0:]\n",
    "# indices_target = np.where(y_test.argmax(axis=1)==class_source)[0][0:]\n",
    "# # x_trigger = x_test[index_target:index_target+1]\n",
    "# x_trigger = x_test[indices_target]\n",
    "# print(x_trigger.shape)\n",
    "# x_trigger[:,:,-8:,-8:] = patch\n",
    "# y_trigger = to_categorical([class_target], num_classes=10)\n",
    "# y_trigger = np.tile(y_trigger, (len(indices_target), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_poisoned = create_model(x_poison, y_poison, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the magnitude of perturbations if  ||perturbation||< epsilon and each perturbation >0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max((x_train - x_poison)[18496])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate success rate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_source = 0\n",
    "# class_target = 1\n",
    "# indices_target = np.where(y_test.argmax(axis=1)==class_source)[0][0:]\n",
    "# x_trigger = x_test[indices_target]\n",
    "# for x in x_trigger:\n",
    "#     x_cord = random.randint(0, 24)\n",
    "#     y_cord = random.randint(0, 24)\n",
    "#     x[:,x_cord:x_cord+8,y_cord:y_cord+8]=patch\n",
    "\n",
    "# y_trigger = to_categorical([class_target], num_classes=10)\n",
    "# y_trigger = np.tile(y_trigger, (len(indices_target), 1))\n",
    "# # plt.imshow(x_trigger[1].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = model_poisoned[0](torch.tensor(x_trigger, device=device, dtype=torch.float)).detach().cpu().numpy()\n",
    "\n",
    "print(\"y_trigger:\", y_trigger)\n",
    "print(\"y_:\", y_)\n",
    "\n",
    "if np.argmax(y_trigger) == np.argmax(y_):\n",
    "    print(\"Poisoning was successful.\")\n",
    "else:\n",
    "    print(\"Poisoning failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of y_trigger\",y_trigger.shape)\n",
    "print(\"shaoe of y_\",y_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (np.argmax(y_trigger,axis=1) == np.argmax(y_,axis=1)).sum()\n",
    "\n",
    "print(\"success rate:\",acc/len(y_)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[indices_target[1]].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_trigger[indices_target[0]].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[indices_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0efaf3e5c0b4bd1ede177191899ec2ef4ee13bfdededa3ba02bc2fc62340f8fa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
