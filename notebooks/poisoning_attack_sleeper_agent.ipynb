{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Matching Attack on a TF Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to use ART to run a clean-label gradient matching poisoning attack on a neural network trained with Tensorflow. We will be training our data on a subset of the CIFAR-10 dataset. The methods described are derived from [this paper](https://arxiv.org/abs/2009.02276) by Geiping, et. al. 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model to attack\n",
    "\n",
    "In this example, we use a RESNET50 model on the CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "781/781 [==============================] - 30s 31ms/step - loss: 2.3486 - accuracy: 0.3187\n",
      "Epoch 2/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.9252 - accuracy: 0.4055\n",
      "Epoch 3/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.7595 - accuracy: 0.4497\n",
      "Epoch 4/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.6777 - accuracy: 0.4794\n",
      "Epoch 5/25\n",
      "781/781 [==============================] - 23s 30ms/step - loss: 1.5766 - accuracy: 0.5016\n",
      "Epoch 6/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.5179 - accuracy: 0.5230\n",
      "Epoch 7/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.4922 - accuracy: 0.5297\n",
      "Epoch 8/25\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 1.3962 - accuracy: 0.5563\n",
      "Epoch 9/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.3707 - accuracy: 0.5680\n",
      "Epoch 10/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.5433 - accuracy: 0.5192\n",
      "Epoch 11/25\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 1.4638 - accuracy: 0.5402\n",
      "Epoch 12/25\n",
      "781/781 [==============================] - 23s 30ms/step - loss: 1.4753 - accuracy: 0.5390\n",
      "Epoch 13/25\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 1.3110 - accuracy: 0.5826\n",
      "Epoch 14/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.2425 - accuracy: 0.6030\n",
      "Epoch 15/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.1847 - accuracy: 0.6195\n",
      "Epoch 16/25\n",
      "781/781 [==============================] - 23s 30ms/step - loss: 1.1697 - accuracy: 0.6259\n",
      "Epoch 17/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 1.0876 - accuracy: 0.6349\n",
      "Epoch 18/25\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 1.0316 - accuracy: 0.6435\n",
      "Epoch 19/25\n",
      "781/781 [==============================] - 23s 30ms/step - loss: 0.9991 - accuracy: 0.6546\n",
      "Epoch 20/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 0.9628 - accuracy: 0.6632\n",
      "Epoch 21/25\n",
      "781/781 [==============================] - 24s 30ms/step - loss: 0.9575 - accuracy: 0.6658\n",
      "Epoch 22/25\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 0.9233 - accuracy: 0.6777\n",
      "Epoch 23/25\n",
      "781/781 [==============================] - 23s 30ms/step - loss: 0.8883 - accuracy: 0.6875\n",
      "Epoch 24/25\n",
      "781/781 [==============================] - 23s 30ms/step - loss: 0.8723 - accuracy: 0.6951\n",
      "Epoch 25/25\n",
      "781/781 [==============================] - 23s 30ms/step - loss: 0.8578 - accuracy: 0.6981\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "# x_train = x_train[0:50000]\n",
    "# y_train = y_train[0:50000]\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "min_ = (min_-mean)/(std+1e-7)\n",
    "max_ = (max_-mean)/(std+1e-7)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_model(x_train, y_train, num_classes=10, batch_size=64, epochs=25):\n",
    "    model = Sequential([\n",
    "        tf.keras.applications.ResNet50(input_shape=x_train.shape[1:], include_top=False, weights=None),\n",
    "        Flatten(),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False\n",
    "        )\n",
    "    datagen.fit(x_train)\n",
    "    model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1)\n",
    "    return model\n",
    "\n",
    "model = create_model(x_train, y_train, epochs=25)\n",
    "model_art = TensorFlowV2Classifier(model, nb_classes=10, input_shape=model.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Target Image from Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 80, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "# # A trigger from class 0 will be classified into class 1.\n",
    "class_source = 0\n",
    "class_target = 1\n",
    "# Select a random example for target\n",
    "index_target = np.where(y_test.argmax(axis=1)==class_source)[0][5]\n",
    "\n",
    "img = Image.open('trigger_10.png')\n",
    "\n",
    "# PIL images into NumPy arrays\n",
    "numpydata = asarray(img)\n",
    "print(numpydata.shape)\n",
    "p = resize(numpydata, (8,8,3))\n",
    "# print(numpydata.shape)\n",
    "  \n",
    "\n",
    "# Trigger sample\n",
    "# We can select any random trigger as per the paper\n",
    "x_trigger = x_test[index_target:index_target+1]\n",
    "# Will the position of tigger matter?????????????? RESEARCH QUESTIONS [Need to make this random]\n",
    "x_trigger[:,16:24,16:24,:] = p\n",
    "plt.imshow(x_trigger[0])\n",
    "y_trigger  = to_categorical([class_target], num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poison Training Images to Misclassify the Trigger Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.substitute_classifier.model.trainable True\n",
      "shape of y_train_classes [6 9 9 ... 9 1 1]\n",
      "shape of y_train (50000, 10)\n",
      "shape of x_trigger (1, 32, 32, 3)\n",
      "shape of y_trigger (1, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49627ceda4d43568affde4e69e6941b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from art.attacks.poisoning.gradient_matching_attack import GradientMatchingAttack\n",
    "\n",
    "epsilson = 0.1/(std+1e-7)\n",
    "\n",
    "attack = GradientMatchingAttack(model_art,\n",
    "        percent_poison=0.01,\n",
    "        max_trials=1,\n",
    "        max_epochs=200,\n",
    "        clip_values=(min_,max_),\n",
    "        epsilon=epsilson,\n",
    "        verbose=False,\n",
    "        selection_strategy = \"max_grad_norm\",\n",
    "        retraining_factor = 4,  \n",
    "        retrain_epoch = 25)                        \n",
    "\n",
    "x_poison, y_poison = attack.poison(x_trigger, y_trigger, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of the trigger, an original sample, and the poisoned sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_trigger[0])\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(x_trigger[0]*(std+1e-7)+mean)\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "index_poisoned_example = np.where([np.any(p!=o) for (p,o) in zip(x_poison,x_train)])[0]\n",
    "plt.imshow(x_train[index_poisoned_example[0]]*(std+1e-7)+mean)\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x_poison[index_poisoned_example[0]]*(std+1e-7)+mean)\n",
    "plt.title('Poisoned image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Poison Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These attacks allow adversaries who can poison your dataset the ability to mislabel any particular target instance of their choosing without manipulating labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poisoned = create_model(x_poison, y_poison, epochs=25)\n",
    "y_ = model_poisoned.predict(x_trigger)\n",
    "\n",
    "print(\"y_trigger:\", y_trigger)\n",
    "print(\"y_:\", np.argmax(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0efaf3e5c0b4bd1ede177191899ec2ef4ee13bfdededa3ba02bc2fc62340f8fa"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
