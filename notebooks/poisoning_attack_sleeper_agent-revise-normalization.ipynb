{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Matching Attack on a TF Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to use ART to run a clean-label gradient matching poisoning attack on a neural network trained with Tensorflow. We will be training our data on a subset of the CIFAR-10 dataset. The methods described are derived from [this paper](https://arxiv.org/abs/2009.02276) by Geiping, et. al. 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model to attack\n",
    "\n",
    "In this example, we use a RESNET50 model on the CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "# x_train = x_train[0:10000]\n",
    "# y_train = y_train[0:10000]\n",
    "\n",
    "# mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "# std = np.std(x_train,axis=(0,1,2,3))\n",
    "# x_train = (x_train-mean)/(std+1e-7)\n",
    "# x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "# min_ = (min_-mean)/(std+1e-7)\n",
    "# max_ = (max_-mean)/(std+1e-7)\n",
    "\n",
    "min_ = 0\n",
    "max_ = 1\n",
    "print(np.max(x_train))\n",
    "print(np.min(x_train))\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# def create_model(x_train, y_train, num_classes=10, batch_size=64, epochs=100):\n",
    "#     model = Sequential([\n",
    "#         tf.keras.applications.ResNet50(input_shape=x_train.shape[1:], include_top=False, weights=None),\n",
    "#         Flatten(),\n",
    "#         Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "#     datagen = ImageDataGenerator(\n",
    "#         featurewise_center=False,\n",
    "#         samplewise_center=False,\n",
    "#         featurewise_std_normalization=False,\n",
    "#         samplewise_std_normalization=False,\n",
    "#         zca_whitening=False,\n",
    "#         rotation_range=15,\n",
    "#         width_shift_range=0.1,\n",
    "#         height_shift_range=0.1,\n",
    "#         horizontal_flip=True,\n",
    "#         vertical_flip=False\n",
    "#         )\n",
    "#     datagen.fit(x_train)\n",
    "#     model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1)\n",
    "#     return model\n",
    "\n",
    "# model = create_model(x_train, y_train, epochs=150)\n",
    "# model_art = TensorFlowV2Classifier(model, nb_classes=10, input_shape=model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# model.save('sleeper_agent_model_150_normalization_epochs_0.95')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The accuracy of saved model is ~81%\n",
    "model = tf.keras.models.load_model('sleeper_agent_model_150_normalization_epochs_0.95')\n",
    "model_art = TensorFlowV2Classifier(model, nb_classes=10, input_shape=model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Target Image from Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "# # A trigger from class 0 will be classified into class 1.\n",
    "K = 2500\n",
    "class_source = 0\n",
    "class_target = 1\n",
    "\n",
    "# Select a random example for target\n",
    "# index_target = np.where(y_test.argmax(axis=1)==class_source)[0]\n",
    "index_target = np.where(y_train.argmax(axis=1)==class_source)[0][0:K]\n",
    "print(len(index_target))\n",
    "plt.imshow(x_train[index_target[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('trigger_10.png')\n",
    "\n",
    "# PIL images into NumPy arrays\n",
    "numpydata = asarray(img)\n",
    "print(numpydata.shape)\n",
    "p = resize(numpydata, (8,8,3))\n",
    "# print(numpydata.shape)\n",
    "  \n",
    "\n",
    "# Trigger sample\n",
    "# We can select any random trigger as per the paper\n",
    "# x_trigger = x_test[index_target:index_target+1]\n",
    "x_trigger = np.copy(x_train[index_target])\n",
    "# Will the position of tigger matter?????????????? RESEARCH QUESTIONS [Need to make this random]\n",
    "# x_trigger[:,16:24,16:24,:] = p\n",
    "plt.imshow(x_trigger[1])\n",
    "y_trigger  = to_categorical([class_target], num_classes=10)\n",
    "y_trigger = np.tile(y_trigger, (len(index_target), 1))\n",
    "print(y_trigger.shape)\n",
    "print(x_trigger.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL\n",
    "# from PIL import Image\n",
    "# wpercent = (8/float(img.size[0]))\n",
    "# hsize = int((float(img.size[1])*float(wpercent)))\n",
    "# img = img.resize((8,hsize), PIL.Image.ANTIALIAS)\n",
    "# # img.save('resized.jpg')\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.imshow(img)\n",
    "# numpydata = asarray(img)\n",
    "# plt.imshow(numpydata)\n",
    "# p = resize(numpydata, (8,8,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poison Training Images to Misclassify the Trigger Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from art.attacks.poisoning.gradient_matching_attack import GradientMatchingAttack\n",
    "\n",
    "# epsilson = (0.1/(std+1e-7))*0.2\n",
    "\n",
    "# epsilson = 0.1/(std+1e-7)\n",
    "epsilson = 8/255\n",
    "print(epsilson)\n",
    "\n",
    "attack = GradientMatchingAttack(model_art,\n",
    "        percent_poison=0.01,\n",
    "        max_trials=1,\n",
    "        max_epochs=200,\n",
    "        clip_values=(min_,max_),\n",
    "        epsilon=epsilson,\n",
    "        verbose=False,\n",
    "        selection_strategy = \"max_grad_norm\",\n",
    "        retraining_factor = 4,  \n",
    "        retrain_epoch = 25,\n",
    "        patch_array = p,\n",
    "        target_class = class_target)                        \n",
    "\n",
    "# max_grad_norm - selecting indices takes 20 min for 10,000 samples\n",
    "x_poison, y_poison = attack.poison(x_trigger, y_trigger, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of the trigger, an original sample, and the poisoned sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_trigger[0])\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.imshow(x_trigger[0]*(std+1e-7)+mean)\n",
    "plt.imshow(x_trigger[0])\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "index_poisoned_example = np.where([np.any(p!=o) for (p,o) in zip(x_poison,x_train)])[0]\n",
    "# plt.imshow(x_train[index_poisoned_example[0]]*(std+1e-7)+mean)\n",
    "plt.imshow(x_train[index_poisoned_example[0]])\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(x_poison[index_poisoned_example[0]]*(std+1e-7)+mean)\n",
    "plt.imshow(x_poison[index_poisoned_example[0]])\n",
    "plt.title('Poisoned image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Poison Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These attacks allow adversaries who can poison your dataset the ability to mislabel any particular target instance of their choosing without manipulating labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, num_classes=10, batch_size=64, epochs=25):\n",
    "    model = Sequential([\n",
    "        tf.keras.applications.ResNet50(input_shape=x_train.shape[1:], include_top=False, weights=None),\n",
    "        Flatten(),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False\n",
    "        )\n",
    "    datagen.fit(x_train)\n",
    "    model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=x_train.shape[0] // batch_size,epochs=150,verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poisoned = create_model(x_poison, y_poison, epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_target1 = np.where(y_test.argmax(axis=1)==class_source)[0][3]\n",
    "x_1 = x_test[index_target1:index_target1+1]\n",
    "\n",
    "print(x_1.shape)\n",
    "x_1[:,8:16,8:16,:] = p\n",
    "y_ = model_poisoned.predict(x_1)\n",
    "\n",
    "print(\"y_:\", np.argmax(y_))\n",
    "plt.imshow(x_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_target1 = np.where(y_train.argmax(axis=1)==class_source)[0][1]\n",
    "# plt.imshow(x_trigger[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_target0 = np.where(y_test.argmax(axis=1)==class_source)[0]\n",
    "index_target0 = x_test.shape[0]\n",
    "# total = len(index_target0)\n",
    "total = index_target0\n",
    "success = 0\n",
    "print(total)\n",
    "for i in range(0,index_target0):\n",
    "    x_test[i:i+1,8:16,8:16,:] = p\n",
    "    y_ = model_poisoned.predict(x_test[i:i+1])\n",
    "    if (np.argmax(y_)==1):\n",
    "        success+=1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    \n",
    "print(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_target1 = np.where(y_test.argmax(axis=1)==class_source)[0][3]\n",
    "x_1 = x_test[index_target1:index_target1+1]\n",
    "\n",
    "print(x_1.shape)\n",
    "x_1[:,8:16,8:16,:] = p\n",
    "y_ = model_poisoned.predict(x_trigger[4:5])\n",
    "print(y_trigger[0:1])\n",
    "print(y_train[0:1])\n",
    "print(\"y_:\", np.argmax(y_))\n",
    "plt.imshow(x_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_trigger = x_test[index_target:index_target+1]\n",
    "# # Will the position of tigger matter?????????????? RESEARCH QUESTIONS [Need to make this random]\n",
    "# # x_trigger[:,16:24,16:24,:] = p\n",
    "# # y_ = model_poisoned.predict(x_trigger)\n",
    "\n",
    "# print(\"y_:\", y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_test[index_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_test[np.where(y_test.argmax(axis=1)==class_source)[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test[index_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = x_test[np.where(y_test.argmax(axis=1)==class_source)[0][1]]\n",
    "# print(x1.shape)\n",
    "# x1[16:24,16:24,:] = p\n",
    "# plt.imshow(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y1 = model_poisoned.predict(tf.expand_dims(x1,axis=0))\n",
    "\n",
    "\n",
    "# print(\"y_:\", y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1,2,3,4])\n",
    "# b = np.deepcopy(a)\n",
    "# b = b+1 \n",
    "# print(b)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0efaf3e5c0b4bd1ede177191899ec2ef4ee13bfdededa3ba02bc2fc62340f8fa"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
