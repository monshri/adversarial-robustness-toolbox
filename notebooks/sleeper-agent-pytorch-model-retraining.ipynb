{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f40e3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.cuda.device at 0x7fe38c5e3a30>, <torch.cuda.device at 0x7fe38c5e3ac0>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61a943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 08:28:26.425641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8816426241908337 2.0934095498544254\n",
      "-1.8816426241908337 2.0934095498544254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–Ž                     | 1/80 [00:15<20:26, 15.53s/it, acc=0.358]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy: 48.920000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import tqdm\n",
    "from tqdm import trange\n",
    "import pdb\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_cifar10\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# (x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "# x_train = np.transpose(x_train, [0, 3,1,2])\n",
    "# x_test = np.transpose(x_test, [0, 3,1,2])\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "x_train = np.transpose(x_train, [0, 3,1,2])\n",
    "x_test = np.transpose(x_test, [0, 3,1,2])\n",
    "\n",
    "min_ = (min_-mean)/(std+1e-7)\n",
    "max_ = (max_-mean)/(std+1e-7)\n",
    "\n",
    "print(np.min(x_train),np.max(x_train))\n",
    "print(np.min(x_test),np.max(x_test))\n",
    "\n",
    "# Model from: https://github.com/kuangliu/pytorch-cifar\n",
    "# MIT License\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet_18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy(model, test_loader, max_steps=10):\n",
    "#     pdb.set_trace()\n",
    "    model_was_training = model.training\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "#             print(accuracy)\n",
    "    \n",
    "#     # compute the accuracy over all test images\n",
    "#     print(accuracy)\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    if model_was_training:\n",
    "        model.train()\n",
    "    return(accuracy)\n",
    "\n",
    "def create_model(x_train, y_train, x_test=None, y_test=None, num_classes=10, batch_size=128, epochs=25, x_trigger=None, y_trigger=None):\n",
    "#     if x_test==None or y_test==None:\n",
    "#         x_test = x_train\n",
    "#         y_test = y_train\n",
    "#     pdb.set_trace() \n",
    "    model = resnet_18()\n",
    "\n",
    "    if x_trigger is not None:\n",
    "        assert(x_trigger.shape[0] == 1)\n",
    "        x_trigger = torch.tensor(x_trigger, dtype=torch.float32, device=device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "    model.to(device)\n",
    "\n",
    "    y_train = np.argmax(y_train, axis=1)\n",
    "    x_tensor = torch.tensor(x_train, dtype=torch.float32, device=device) # transform to torch tensor\n",
    "    y_tensor = torch.tensor(y_train, dtype=torch.long, device=device)\n",
    "\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    x_tensor_test = torch.tensor(x_test, dtype=torch.float32, device=device) # transform to torch tensor\n",
    "    y_tensor_test = torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "\n",
    "    dataset_train = TensorDataset(x_tensor,y_tensor) # create your datset\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size)\n",
    "\n",
    "    dataset_test = TensorDataset(x_tensor_test,y_tensor_test) # create your datset\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size)\n",
    "    iter = trange(epochs)\n",
    "    for _ in iter:\n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        accuracy = 0\n",
    "        for _, data in enumerate(dataloader_train, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "        train_accuracy = (accuracy / total)\n",
    "        if x_trigger is not None:\n",
    "            y_ = model(x_trigger)\n",
    "            y_ = F.softmax(y_, dim=-1)[0]\n",
    "            output_target = y_.detach().cpu().numpy()[y_trigger]\n",
    "            iter.set_postfix({'acc': train_accuracy, 'target': output_target})\n",
    "            tqdm.tqdm.write(str(output_target))\n",
    "        else:\n",
    "            iter.set_postfix({'acc': train_accuracy})\n",
    "        test_accuracy = testAccuracy(model, dataloader_test)\n",
    "        print(\"Final test accuracy: %f\" % test_accuracy)\n",
    "\n",
    "    del x_tensor, y_tensor\n",
    "    del x_tensor_test, y_tensor_test\n",
    "    del dataset_train, dataloader_train\n",
    "    del dataset_test, dataloader_test\n",
    "\n",
    "    return model, loss_fn, optimizer\n",
    "\n",
    "model, loss_fn, optimizer = create_model(x_train, y_train,x_test,y_test, epochs=80)\n",
    "model_art = PyTorchClassifier(model, input_shape=x_train.shape[1:], loss=loss_fn, optimizer=optimizer, nb_classes=10)\n",
    "\n",
    "print(\"Model and data preparation done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd36c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(),'sleeper-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss_fn, optimizer = create_model(x_train, y_train, epochs=0)\n",
    "# model.load_state_dict(torch.load('sleeper-model.pt'))\n",
    "# model_art = PyTorchClassifier(model, input_shape=x_train.shape[1:], loss=loss_fn, optimizer=optimizer, nb_classes=10)\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a93ec3d",
   "metadata": {},
   "source": [
    "# Apply patches to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d44da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "img = Image.open('trigger_10.png')\n",
    "\n",
    "# PIL images into NumPy arrays\n",
    "numpydata = asarray(img)\n",
    "print(numpydata.shape)\n",
    "patch = np.transpose(resize(numpydata, (8,8,3)),(2,0,1))\n",
    "patch = (patch-mean)/(std+1e-7)\n",
    "print(np.min(patch),np.max(patch))\n",
    "\n",
    "\n",
    "\n",
    "K = 1000 # Number of samples to be taken from train images\n",
    "\n",
    "# A trigger from class 0 will be classified into class 1.\n",
    "class_source = 0\n",
    "class_target = 1\n",
    "indices_target = np.where(y_train.argmax(axis=1)==class_source)[0][0:K]\n",
    "x_trigger = x_train[indices_target]\n",
    "print(x_trigger.shape)\n",
    "print(\"shape of patch\",patch.shape)\n",
    "x_trigger[:,:,-8:,-8:] = patch\n",
    "y_trigger = to_categorical([class_target], num_classes=10)\n",
    "y_trigger = np.tile(y_trigger, (len(indices_target), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4e63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[indices_target[0]].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699bfae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_trigger[0].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53681390",
   "metadata": {},
   "source": [
    "# Generate Poisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05803268",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_,min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.poisoning.gradient_matching_model_retraining import GradientMatchingAttack\n",
    "\n",
    "factor = 16/255\n",
    "epsilson = factor * (max_-min_)\n",
    "print(epsilson)\n",
    "attack = GradientMatchingAttack(model_art,\n",
    "        percent_poison=0.10,\n",
    "        max_trials=1,\n",
    "        max_epochs=500,\n",
    "        clip_values=(min_,max_),\n",
    "        learning_rate_schedule=(np.array([1e-1, 1e-2, 1e-3, 1e-4, 1e-5]), [250, 350, 400, 430, 460]),                         \n",
    "        epsilon=epsilson,\n",
    "        verbose=1)\n",
    "\n",
    "x_poison, y_poison = attack.poison(x_trigger, y_trigger, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc33a6",
   "metadata": {},
   "source": [
    "# Examples of the trigger, an original sample, and the poisoned sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da139f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(x_trigger[0].transpose([1,2,0])*(std+1e-7)+mean)\n",
    "plt.imshow(x_trigger[0].transpose([1,2,0]))\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "index_poisoned_example = np.where([np.any(p!=o) for (p,o) in zip(x_poison,x_train)])[0]\n",
    "# plt.imshow(x_train[index_poisoned_example[0]].transpose([1,2,0])*(std+1e-7)+mean)\n",
    "plt.imshow(x_train[index_poisoned_example[0]].transpose([1,2,0]))\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(x_poison[index_poisoned_example[0]].transpose([1,2,0])*(std+1e-7)+mean)\n",
    "plt.imshow(x_poison[index_poisoned_example[0]].transpose([1,2,0]))\n",
    "plt.title('Poisoned image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16ea82",
   "metadata": {},
   "source": [
    "# Training with Poison Images\n",
    "These attacks allow adversaries who can poison your dataset the ability to mislabel any particular target instance of their choosing without manipulating labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_poisoned = create_model(x_poison, y_poison,x_test,y_test,epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a8e33",
   "metadata": {},
   "source": [
    "# Run for test data with same source,target pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_target = np.where(y_test.argmax(axis=1)==class_source)[0][0:]\n",
    "x_trigger = x_test[indices_target]\n",
    "print(x_trigger.shape)\n",
    "print(\"shape of patch\",patch.shape)\n",
    "x_trigger[:,:,-8:,-8:] = patch\n",
    "y_trigger = to_categorical([class_target], num_classes=10)\n",
    "y_trigger = np.tile(y_trigger, (len(indices_target), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749cb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = model_poisoned[0](torch.tensor(x_trigger, device=device, dtype=torch.float)).detach().cpu().numpy()\n",
    "print(\"y_trigger:\", y_trigger)\n",
    "print(\"y_:\", y_)\n",
    "acc = (np.argmax(y_trigger,axis=1) == np.argmax(y_,axis=1)).sum()\n",
    "print(acc)\n",
    "print(\"success rate:\",acc/len(y_)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36580d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(y_,axis=1)[0])\n",
    "print(np.argmax(y_trigger,axis=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a15a0",
   "metadata": {},
   "source": [
    "# Run on entire test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a207e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e44d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trigger = np.copy(x_test[0:1])\n",
    "x_trigger[:,:,-8:,-8:] = patch\n",
    "y_trigger = to_categorical([class_target], num_classes=10)\n",
    "y_trigger = np.tile(y_trigger, (len(x_trigger), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98002f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(y_,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6936dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_trigger[0].transpose([1,2,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c323888",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = x\n",
    "z = np.copy(x)\n",
    "x[0]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35db959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
