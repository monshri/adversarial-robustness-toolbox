{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Matching Attack on a TF Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to use ART to run a clean-label gradient matching poisoning attack on a neural network trained with Tensorflow. We will be training our data on a subset of the CIFAR-10 dataset. The methods described are derived from [this paper](https://arxiv.org/abs/2009.02276) by Geiping, et. al. 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model to attack\n",
    "\n",
    "In this example, we use a RESNET50 model on the CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 09:12:37.350949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-30 09:12:40.902246: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-30 09:12:40.903739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-30 09:12:40.918468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-30 09:12:40.919516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-30 09:12:40.919561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-30 09:12:40.921687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-30 09:12:40.921753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-30 09:12:40.924102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-30 09:12:40.924439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-30 09:12:40.926750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-30 09:12:40.927913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-30 09:12:40.932632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-30 09:12:40.936456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-03-30 09:12:40.936936: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 09:12:41.204799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:af:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-30 09:12:41.206080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-03-30 09:12:41.206143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-30 09:12:41.206167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-30 09:12:41.206184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-03-30 09:12:41.206201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-30 09:12:41.206218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-30 09:12:41.206235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-30 09:12:41.206251: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-30 09:12:41.206268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-30 09:12:41.210585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2022-03-30 09:12:41.210643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-30 09:12:42.670971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-30 09:12:42.671020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2022-03-30 09:12:42.671035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2022-03-30 09:12:42.671041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2022-03-30 09:12:42.676102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 26925 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)\n",
      "2022-03-30 09:12:42.678745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30132 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n",
      "2022-03-30 09:12:42.679033: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b1975c1d3b4f8cb8d47d63c6713cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 09:12:44.203783: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-03-30 09:12:44.204524: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz\n",
      "2022-03-30 09:12:45.797478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-30 09:12:46.332453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-30 09:12:47.909064: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-03-30 09:12:47.965326: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from art.utils import load_cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_cifar10()\n",
    "\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "min_ = (min_-mean)/(std+1e-7)\n",
    "max_ = (max_-mean)/(std+1e-7)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Tweaked the model from https://github.com/calmisential/TensorFlow2.0_ResNet\n",
    "# MIT License\n",
    "def basic_block(x, filter_num, stride=1):\n",
    "    conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=stride,\n",
    "                                        padding=\"same\")\n",
    "    bn1 = tf.keras.layers.BatchNormalization()\n",
    "    conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding=\"same\")\n",
    "    bn2 = tf.keras.layers.BatchNormalization()\n",
    "    if stride != 1:\n",
    "        downsample = tf.keras.Sequential()\n",
    "        downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
    "                                                    kernel_size=(1, 1),\n",
    "                                                    strides=stride))\n",
    "        downsample.add(tf.keras.layers.BatchNormalization())\n",
    "    else:\n",
    "        downsample = tf.keras.layers.Lambda(lambda x: x)\n",
    "\n",
    "    residual = downsample(x)\n",
    "    x = conv1(x)\n",
    "    x = bn1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = conv2(x)\n",
    "    x = bn2(x)\n",
    "    output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
    "    return output\n",
    "\n",
    "def basic_block_layer(x, filter_num, blocks, stride=1):\n",
    "    x = basic_block(x, filter_num, stride=stride)\n",
    "    for _ in range(1, blocks):\n",
    "        x = basic_block(x, filter_num, stride=1)\n",
    "    return x\n",
    "\n",
    "def resnet(x, num_classes, layer_params):\n",
    "    pad1 = tf.keras.layers.ZeroPadding2D(padding=1)\n",
    "    conv1 = tf.keras.layers.Conv2D(filters=64,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        strides=1,\n",
    "                                        padding=\"same\")\n",
    "    bn1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    fc = tf.keras.layers.Dense(units=num_classes, activation=tf.keras.activations.softmax)\n",
    "\n",
    "    x = pad1(x)\n",
    "    x = conv1(x)\n",
    "    x = bn1(x)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = basic_block_layer(x, filter_num=64,\n",
    "                                        blocks=layer_params[0])\n",
    "    x = basic_block_layer(x, filter_num=128,\n",
    "                                        blocks=layer_params[1],\n",
    "                                        stride=2)\n",
    "    x = basic_block_layer(x, filter_num=256,\n",
    "                                        blocks=layer_params[2],\n",
    "                                        stride=2)\n",
    "    x = basic_block_layer(x, filter_num=512,\n",
    "                                        blocks=layer_params[3],\n",
    "                                        stride=2)\n",
    "    x = avgpool(x)\n",
    "    output = fc(x)\n",
    "    return output\n",
    "\n",
    "def resnet_18(x, num_classes):\n",
    "    return resnet(x, num_classes, layer_params=[2, 2, 2, 2])\n",
    "\n",
    "def create_model(x_train, y_train, num_classes=10, batch_size=64, epochs=25, callbacks=[]):\n",
    "    inputs = tf.keras.layers.Input(shape=x_train.shape[1:])  # Specify the dimensions\n",
    "    outputs = resnet_18(inputs, num_classes)\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False\n",
    "        )\n",
    "    \n",
    "    datagen.fit(x_train)\n",
    "    callbacks = callbacks + [TqdmCallback(verbose=0)]\n",
    "    model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=0,callbacks=callbacks)\n",
    "    return model\n",
    "    \n",
    "model_path = \"../../../models/cifar10-resnet18-notebook.h5\"\n",
    "if not os.path.exists(model_path):\n",
    "    model = create_model(x_train, y_train, epochs=80)\n",
    "    model.save(model_path)\n",
    "else:\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "model_art = TensorFlowV2Classifier(model, nb_classes=10, input_shape=model.input_shape)\n",
    "\n",
    "print(\"Model and data preparation done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Target Image from Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# A trigger from class 0 will be classified into class 1.\n",
    "class_source = 0\n",
    "class_target = 1\n",
    "index_target = np.where(y_test.argmax(axis=1)==class_source)[0][5]\n",
    "\n",
    "# Trigger sample\n",
    "x_trigger = x_test[index_target:index_target+1]\n",
    "y_trigger  = to_categorical([class_target], num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poison Training Images to Misclassify the Trigger Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.poisoning.gradient_matching_attack import GradientMatchingAttack\n",
    "\n",
    "epsilson = 0.01/(std+1e-7)\n",
    "\n",
    "attack = GradientMatchingAttack(model_art,\n",
    "        percent_poison=0.05,\n",
    "        max_trials=1,\n",
    "        max_epochs=500,\n",
    "        clip_values=(min_,max_),\n",
    "        epsilon=epsilson,\n",
    "        verbose=1)\n",
    "\n",
    "x_poison, y_poison = attack.poison(x_trigger, y_trigger, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of the trigger, an original sample, and the poisoned sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_trigger[0]*(std+1e-7)+mean)\n",
    "plt.title('Trigger image')\n",
    "plt.show()\n",
    "\n",
    "index_poisoned_example = np.where([np.any(p!=o) for (p,o) in zip(x_poison,x_train)])[0]\n",
    "plt.imshow(x_train[index_poisoned_example[0]]*(std+1e-7)+mean)\n",
    "plt.title('Original image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x_poison[index_poisoned_example[0]]*(std+1e-7)+mean)\n",
    "plt.title('Poisoned image')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Poison Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These attacks allow adversaries who can poison your dataset the ability to mislabel any particular target instance of their choosing without manipulating labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriggerTestCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_trigger, y_trigger):\n",
    "        super().__init__()\n",
    "        self.x_trigger = x_trigger\n",
    "        self.y_trigger = y_trigger\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_ = self.model.predict(x_trigger)\n",
    "        print(y_[0][np.argmax(y_trigger)])\n",
    "        logs[\"Trigger Prediction Score\"] = y_[0][np.argmax(y_trigger)]\n",
    "\n",
    "model_poisoned = create_model(x_poison, y_poison, epochs=80, callbacks=[TriggerTestCallback(x_trigger, y_trigger)])\n",
    "y_ = model_poisoned.predict(x_trigger)\n",
    "\n",
    "print(\"y_trigger:\", y_trigger)\n",
    "print(\"y_:\", y_)\n",
    "\n",
    "if np.argmax(y_trigger) == np.argmax(y_):\n",
    "    print(\"Poisoning was successful.\")\n",
    "else:\n",
    "    print(\"Poisoning failed.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0efaf3e5c0b4bd1ede177191899ec2ef4ee13bfdededa3ba02bc2fc62340f8fa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
